{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from pprint import pp\n",
    "\n",
    "def episodes_month(month):\n",
    "    # URL de la page Web contenant les données des épisodes\n",
    "    url = f\"https://www.spin-off.fr/calendrier_des_series.html?date=2023-{month}\"\n",
    "\n",
    "    # Effectuer une requête HTTP pour obtenir le contenu de la page\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Trouver la table contenant les données des épisodes (la 8ème table dans ce cas)\n",
    "    tables = soup.find_all(\"table\", class_=\"padding2\")\n",
    "    if len(tables) >= 8:\n",
    "        target_table = tables[7]\n",
    "\n",
    "    # Initialiser une liste pour stocker les données des épisodes\n",
    "    episodes_data = []\n",
    "\n",
    "    # Parcourir les lignes de la table et extraire les informations nécessaires\n",
    "    for index, row in enumerate(target_table.find_all(\"tr\"), 1):\n",
    "        if index == 1:\n",
    "            pass  # Ignorer la première ligne qui contient les en-têtes\n",
    "        else:\n",
    "            cells = row.find_all(\"td\", class_=\"td_jour\")\n",
    "\n",
    "            for cell in cells:\n",
    "                # Extraire la date de l'épisode à partir de l'attribut 'id' du div_jour\n",
    "                div_jour = cell.find('div', class_='div_jour')\n",
    "                if div_jour:\n",
    "                    episode_id = div_jour['id']\n",
    "                    day = episode_id.split('jour_')[1]\n",
    "\n",
    "                # Extraire les détails de l'épisode à partir des balises <a> dans la cellule\n",
    "                for episode in cell.find_all('span', class_='calendrier_episodes'):\n",
    "                    spanContent = episode.find_all('a')\n",
    "                    episode_name = spanContent[0].text\n",
    "                    episode_season = spanContent[1].text.split('.')[0]\n",
    "                    episode_number = spanContent[1].text.split('.')[1]\n",
    "\n",
    "                    # Extraire le nom du pays et de la chaîne à partir des balises <img> précédentes\n",
    "                    channel = episode.find_previous('img')['alt']\n",
    "                    country = episode.find_previous('img').find_previous('img')['alt']\n",
    "\n",
    "                    # Extraire l'URL de la classe \"liens\"\n",
    "                    episode_url = spanContent[1]['href']\n",
    "                    episode_url = episode_url.replace(\"https://www.spin-off.fr/\", \"\")\n",
    "\n",
    "                    # Ajouter les données de l'épisode à la liste episodes_data\n",
    "                    episodes_data.append({\n",
    "                        'name': episode_name,\n",
    "                        'episode_number': episode_number,\n",
    "                        'episode_season': episode_season,\n",
    "                        'date': day,\n",
    "                        'country': country,\n",
    "                        'channel': channel,\n",
    "                        'url': episode_url  # Ajouter l'URL de la page de l'épisode (sans le préfixe)\n",
    "                    })\n",
    "\n",
    "    # Écrire les données dans un fichier CSV\n",
    "    # with open('data/files/episodes_october.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    #     fieldnames = ['name', 'episode_number', 'episode_season', 'date', 'country', 'channel', 'url']\n",
    "    #     writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    #     writer.writeheader()\n",
    "    #     writer.writerows(episodes_data)\n",
    "\n",
    "    # Afficher les données extraites\n",
    "    return episodes_data\n",
    "\n",
    "episodes_october = episodes_month(10)\n",
    "def count_by_attribute(episodes, attribute):\n",
    "    count_per_attribute = {}\n",
    "    for episode in episodes:\n",
    "        attr = episode[attribute]\n",
    "        if attr not in count_per_attribute:\n",
    "            count_per_attribute[attr] = 1\n",
    "        else:\n",
    "            count_per_attribute[attr] += 1\n",
    "\n",
    "    sorted_channels = sorted(count_per_attribute.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_channels = sorted_channels[:3]\n",
    "\n",
    "    with open('README.md', 'a+', encoding='utf-8') as file:\n",
    "        file.write(\"Trois chaînes qui ont diffusé le plus d'épisodes :\\n\")\n",
    "        for channel, episode_count in top_channels:\n",
    "            file.write(f\"{channel}: {episode_count} épisodes\\n\")\n",
    "\n",
    "    return top_channels\n",
    "\n",
    "# Utilisation de la fonction pour compter et trier les épisodes par chaîne\n",
    "top_channels = count_by_attribute(episodes_october, 'channel')\n",
    "top_country = count_by_attribute(episodes_october, 'country')\n",
    "# # Utilisation pour les chaînes et les pays\n",
    "# channels_with_max_episodes, max_episodes = count_by_attribute(episodes_october, 'channel')\n",
    "# countries_with_max_episodes, max_episodes_country = count_by_attribute(episodes_october, 'country')\n",
    "\n",
    "\n",
    "def frequency_words():\n",
    "    # Supposons que vous avez une liste de noms de séries uniques nommée unique_series_names\n",
    "\n",
    "    # Création d'une liste de noms de séries uniques\n",
    "    unique_series_names = set()  # Initialise un ensemble pour les noms de séries uniques\n",
    "\n",
    "    # Récupération des noms uniques des séries\n",
    "    for episode in episodes_october:\n",
    "        unique_series_names.add(episode['name'])  # Ajoute le nom de la série à l'ensemble\n",
    "\n",
    "    # Analyse des mots dans les noms de séries\n",
    "    word_frequency = {}\n",
    "    for series_name in unique_series_names:\n",
    "        words = series_name.lower().split()  # Sépare les mots et les met en minuscules\n",
    "        for word in words:\n",
    "            if word in word_frequency:\n",
    "                word_frequency[word] += 1\n",
    "            else:\n",
    "                word_frequency[word] = 1\n",
    "\n",
    "    # Trie les mots par fréquence\n",
    "    sorted_words = sorted(word_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Écrire les mots les plus fréquents dans le fichier README.md\n",
    "    # with open('README.md', 'a+', encoding='utf-8') as file:\n",
    "    #     file.write(\"Mots les plus fréquents dans les noms des séries :\\n\")\n",
    "    #     for word, frequency in sorted_words[:15]:  # Écrire les 10 mots les plus fréquents\n",
    "    #         file.write(f\"{word}: {frequency} occurrences\\n\")\n",
    "frequency_words()\n",
    "\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Fonction pour organiser les chaines par jour\n",
    "# def channels_by_day(episodes):\n",
    "#     episodes.sort(key=lambda x: datetime.strptime(x['date'], '%d-%m-%Y'))  # Trie les épisodes par date\n",
    "\n",
    "#     episodes_per_day = {}\n",
    "#     for episode in episodes:\n",
    "#         current_day = episode['date']\n",
    "#         if current_day not in episodes_per_day:\n",
    "#             episodes_per_day[current_day] = {'channels': set()}\n",
    "\n",
    "#         episodes_per_day[current_day]['channels'].add(episode['channel'])\n",
    "#         # episodes_per_day[current_day]['episodes'].append(episode)\n",
    "\n",
    "#     return episodes_per_day\n",
    "\n",
    "# # Utilisation de la fonction pour obtenir les épisodes par jour\n",
    "# channels_by_day = channels_by_day(episodes_october)\n",
    "# pp(channels_by_day)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
